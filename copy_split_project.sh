#!/usr/bin/env bash
# ---------------------------------------------------------------------------
# split_podcast_min.sh â€“ "ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ Podcast è‡ªå‹•ç”Ÿæˆ" ã®æœ€å°æ§‹æˆ
#   ç”»åƒå…¥åŠ›ãƒ»å‹•ç”»ç·¨é›†ã‚’å®Œå…¨ã«æ’é™¤ã—ã€
#   â‘  GPT ã§å¯¾è©±ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ â†’ â‘¡ ElevenLabs TTS ã§éŸ³å£°åŒ– â†’ â‘¢ mp3 çµåˆ
#   ã¾ã§ã‚’ 1 ã‚³ãƒãƒ³ãƒ‰ã§è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
#   ï¼ˆauto_podcast ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼‰
# ---------------------------------------------------------------------------
set -euo pipefail
cd "$(dirname "$0")"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ base config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat > config.py <<'PY'
# config.py  â€“ 2 ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ç”¨ãƒœã‚¤ã‚¹ã‚’å…¨è¨€èªã§åˆ†é›¢
from pathlib import Path
from dotenv import load_dotenv
import os

load_dotenv()

# â”€â”€ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE   = Path(__file__).parent
INPUT  = BASE / "input"
OUTPUT = BASE / "output"
TEMP   = BASE / "temp"
for d in (INPUT, OUTPUT, TEMP): d.mkdir(exist_ok=True)

# â”€â”€ API ã‚­ãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY      = os.getenv("OPENAI_API_KEY")
UNSPLASH_ACCESS_KEY = os.getenv("UNSPLASH_ACCESS_KEY", "")

# â”€â”€ OpenAI TTS ç”¨ (Alice ç”¨, Bob ç”¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VOICE_MAP = {
    "en": ("alloy",   "echo"),     # è‹±èª : è½ã¡ç€ã„ãŸç”·æ€§ / è½ã¡ç€ã„ãŸå¥³æ€§
    "ja": ("nova",    "shimmer"),  # æ—¥æœ¬èª : å¥³æ€§ / ä¸­æ€§
    "pt": ("fable",   "onyx"),     # ãƒãƒ«ãƒˆã‚¬ãƒ«èª : ã‚„ã‚„æ˜ã‚‹ã„ / ä½ã‚
    "id": ("alloy",   "fable"),    # ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª : è½ã¡ç€ã / æ˜ã‚‹ã‚
}
# å¿…è¦ã«å¿œã˜ã¦ãƒœã‚¤ã‚¹åã¯è‡ªç”±ã«å·®ã—æ›¿ãˆã¦ãã ã•ã„
PY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ dialogue generator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat > dialogue.py <<'PY'
# dialogue.py
"""Generate a two-person *discussion / debate* script via GPT-4o in any language."""

from openai import OpenAI
from config import OPENAI_API_KEY
from typing import List, Tuple

openai = OpenAI(api_key=OPENAI_API_KEY)

def make_dialogue(topic: str, lang: str, turns: int = 8) -> List[Tuple[str, str]]:
    """
    topic : è­°è«–ãƒ†ãƒ¼ãƒ
    lang  : 'en', 'ja', 'pt', 'id' â€¦ å‡ºåŠ›è¨€èªã‚³ãƒ¼ãƒ‰
    turns : Aliceâ†’Bob ã®å¾€å¾©å›æ•°ï¼ˆ1 å¾€å¾© = 2 è¡Œï¼‰
    æˆ»ã‚Šå€¤: [(speaker, text), ...]  â€»å¿…ãš len == turns*2
    """
    prompt = (
        f"Stage a lively *discussion* between Alice and Bob in {lang}.\n"
        f"Topic: \"{topic}\". Exactly {turns} exchanges (Alice starts).\n\n"
        "â€¢ Each utterance should present a clear standpoint, argument, or rebuttal.\n"
        "â€¢ Friendly tone but contrasting opinions when appropriate.\n"
        "â€¢ 20â€“35 words per line.\n"
        "â€¢ Return ONLY the dialogue, one line each, formatted as:\n"
        "  Alice: ...\n  Bob:   ...\n"
    )
    rsp = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )

    raw_lines = [
        l.strip() for l in rsp.choices[0].message.content.splitlines()
        if l.strip().startswith(("Alice:", "Bob:"))
    ]

    # ---- å¿…è¦æ•°ã«ãƒˆãƒªãƒŸãƒ³ã‚° / ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° --------------------------
    max_lines = turns * 2                     # æœŸå¾…è¡Œæ•°
    raw_lines = raw_lines[:max_lines]         # ä½™åˆ†ã‚’ã‚«ãƒƒãƒˆ

    while len(raw_lines) < max_lines:         # è¶³ã‚Šãªã‘ã‚Œã°è£œå®Œ
        speaker = "Alice" if len(raw_lines) % 2 == 0 else "Bob"
        raw_lines.append(f"{speaker}: ...")

    # ---- æ•´å½¢ã—ã¦è¿”å´ -------------------------------------------
    return [(spk.strip(), txt.strip())
            for spk, txt in (ln.split(":", 1) for ln in raw_lines)]

PY
cat > combos.yaml <<'PY'
combos:
  - audio: en
    subs:  [en, pt]
    account: acc1       # â† 1 æœ¬ç›®ç”¨ãƒˆãƒ¼ã‚¯ãƒ³

  - audio: en
    subs:  [en, id]
    account: acc2       # â† 2 æœ¬ç›®ç”¨

  - audio: en
    subs:  [en, ja]
    account: acc3       # â† 3 æœ¬ç›®ç”¨

  # combos.yaml â”€ è¿½åŠ åˆ†ã ã‘æŠœç²‹
  - audio: ja          # æ—¥æœ¬èªéŸ³å£°
    subs:  [ja, en]    # ä¸Šæ®µ: æ—¥æœ¬èªã€€ä¸‹æ®µ: è‹±èª
    account: acc4      # â† acc4 ç”¨ãƒˆãƒ¼ã‚¯ãƒ³

  - audio: ja
    subs: [ja, ko]     # ä¸Šæ®µ: æ—¥æœ¬èªã€€ä¸‹æ®µ: éŸ“å›½èª
    account: acc5

  - audio: ja
    subs: [ja, id]     # ä¸Šæ®µ: æ—¥æœ¬èªã€€ä¸‹æ®µ: ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èª
    account: acc6
PY

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tts module â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat > tts.py <<'PY'
from pathlib import Path
from elevenlabs import generate as tts_gen
from config import ELEVEN_API_KEY, VOICE_A, VOICE_B

# -------------------------------------------------
# å…¬é–‹ã‚µãƒ³ãƒ—ãƒ«ã®éŸ³å£° IDï¼ˆç„¡æ–™æ ã§åˆ©ç”¨å¯ï¼‰
# ä½¿ã„ãŸã„å£°ãŒã‚ã‚Œã°ã“ã“ã‹ .env ã§ä¸Šæ›¸ãã—ã¦ãã ã•ã„
VOICE_MAP = {
    "Rachel": "21m00Tcm4TlvDq8ikWAM",
    "Adam":   "OmEnGXU7trwJsZ3jMPl8",
}
# -------------------------------------------------

def line_to_voice(speaker: str, text: str, out: Path):
    """
    speaker : 'Alice' ã¾ãŸã¯ 'Bob' ãªã©
    text    : ã‚»ãƒªãƒ•
    out     : mp3 æ›¸ãå‡ºã—å…ˆ Path
    """
    # 1) .env ã® VOICE_A / VOICE_B ã‚’æœ€å„ªå…ˆ
    if speaker.lower() == "alice":
        vid = VOICE_A or VOICE_MAP["Rachel"]
    else:
        vid = VOICE_B or VOICE_MAP["Adam"]

    # 2) fallback â€” ä¸‡ä¸€ ID ãŒç©ºãªã‚‰å…¬é–‹ ID ã‚’ä½¿ç”¨
    if not vid:
        vid = VOICE_MAP["Rachel"]

    # 3) ElevenLabs ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    if not ELEVEN_API_KEY:
        raise RuntimeError("ELEVENLABS_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    out.write_bytes(
        tts_gen(
            api_key=ELEVEN_API_KEY,
            text=text,
            voice=vid,
        )
    )
PY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ podcast builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat > topic_picker.py <<'PY'
name: Auto-Podcast-Daily

on:
  schedule:
    - cron: "15 3 * * *"   # æ¯æ—¥ UTC 03:15 â‰’ JST 12:15
  workflow_dispatch:       # æ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼ã‚‚å¯

jobs:
  build-upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Restore YouTube token
        env:
          YT_TOKEN_B64: ${{ secrets.YOUTUBE_TOKEN_PKL }}
        run: |
          mkdir -p tokens
          echo "$YT_TOKEN_B64" | base64 -d > tokens/token_default.pkl

      - name: Pick topic
        id: topic
        run: |
          TOPIC=$(python topic_picker.py)
          echo "topic=$TOPIC" >> $GITHUB_OUTPUT

      - name: Generate & upload
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
        run: |
          python main.py "${{ steps.topic.outputs.topic }}" --turns 6 --privacy public

PY

cat > tts_openai.py <<'PY'
# tts_openai.py
"""OpenAI TTS wrapper â€“ language-aware & two-speaker support."""

from pathlib import Path
from openai import OpenAI
from config import OPENAI_API_KEY, VOICE_MAP

client = OpenAI(api_key=OPENAI_API_KEY)

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆè¨€èªãŒ VOICE_MAP ã«ç„¡ã„å ´åˆï¼‰
FALLBACK_VOICES = ("alloy", "echo")  # (Alice, Bob)

def speak(lang: str, speaker: str, text: str, out_path: Path):
    """
    lang     : 'en', 'ja', 'pt', 'id' ãªã©
    speaker  : 'Alice' / 'Bob' ã§å£°ã‚’åˆ‡æ›¿
    text     : ã‚»ãƒªãƒ•
    out_path : æ›¸ãå‡ºã—å…ˆ .mp3
    """
    v_a, v_b = VOICE_MAP.get(lang, FALLBACK_VOICES)
    voice_id = v_a if speaker.lower() == "alice" else v_b

    resp = client.audio.speech.create(
        model="tts-1",          # é«˜éŸ³è³ªã¯ "tts-1-hd"
        voice=voice_id,
        input=text
    )
    out_path.write_bytes(resp.content)

PY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ podcast builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat > podcast.py <<'PY'
from pathlib import Path
from pydub import AudioSegment

def concat_mp3(parts:list[Path],out:Path):
    merged=AudioSegment.empty()
    for p in parts:
        merged+=AudioSegment.from_file(p)
    merged.export(out,format="mp3")
PY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat > bg_image.py <<'PY'
"""
bg_image.py â€“ Unsplash ã‹ã‚‰æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ **æ¨ªå‘ã** ç”»åƒã‚’å–å¾—ã—ï¼Œ
ä¸­å¤®ãƒˆãƒªãƒ ã—ã¦ 1920Ã—1080 PNG ã‚’ç”Ÿæˆï¼ˆå¤±æ•—æ™‚ã¯å˜è‰²ï¼‰ã€‚
"""
from pathlib import Path
import logging, io, requests
from PIL import Image, ImageOps
from config import UNSPLASH_ACCESS_KEY

# ------------------------------------------------------------
W, H = 1920, 1080        # æ¨ªå‹•ç”» Full-HD è§£åƒåº¦

def fetch(topic: str, out_png: Path) -> bool:
    """
    Unsplash Random API ã§æ¨ªå‘ã (landscape) ç”»åƒã‚’å–å¾—ã—ï¼Œ
    1920Ã—1080 ã«ãƒ•ã‚£ãƒƒãƒˆã•ã›ã¦ä¿å­˜ã™ã‚‹ã€‚
    """
    if not UNSPLASH_ACCESS_KEY:
        logging.warning("[Unsplash] KEY æœªè¨­å®š â†’ å˜è‰²èƒŒæ™¯")
        _fallback_solid(out_png)
        return False

    url = (
        "https://api.unsplash.com/photos/random"
        f"?query={requests.utils.quote(topic)}"
        f"&orientation=landscape&client_id={UNSPLASH_ACCESS_KEY}"
    )
    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        img_url   = r.json()["urls"]["regular"]
        img_bytes = requests.get(img_url, timeout=15).content
        _resize_1920x1080(img_bytes, out_png)
        return True
    except Exception as e:
        logging.exception("[Unsplash] %s", e)
        _fallback_solid(out_png)
        return False

# ------------------------------------------------------------
def _resize_1920x1080(img_bytes: bytes, out_png: Path):
    """ImageOps.fit ã§é»’å¸¯ãªã—ä¸­å¤®ãƒ•ã‚£ãƒƒãƒˆ â†’ 1920Ã—1080 ã§ä¿å­˜"""
    with Image.open(io.BytesIO(img_bytes)) as im:
        fitted = ImageOps.fit(im, (W, H), Image.LANCZOS, centering=(0.5, 0.5))
        fitted.save(out_png, "PNG", optimize=True)

# å˜è‰²ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
def _fallback_solid(out_png: Path, color=(10, 10, 10)):
    Image.new("RGB", (W, H), color).save(out_png, "PNG")
PY

cat > subtitle_video.py <<'PY'
# ================= subtitle_video.py =================
from moviepy import (
    ImageClip, TextClip, AudioFileClip, ColorClip, concatenate_videoclips
)
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
import os, unicodedata as ud, re, textwrap
from pathlib import Path

# ---------- ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ----------
FONT_DIR  = Path(__file__).parent / "fonts"
FONT_LATN = str(FONT_DIR / "RobotoSerif_36pt-Bold.ttf")
FONT_JP   = str(FONT_DIR / "NotoSansJP-Bold.ttf")
FONT_KO   = str(FONT_DIR / "malgunbd.ttf")

# ---------- X ä½ç½®ãšã‚‰ã— ----------
SHIFT_X = 0                    # æ¨ªå‹•ç”»ãªã®ã§ä¸­å¤®å¯„ã›
def xpos(w: int) -> int:
    return (SCREEN_W - w) // 2 + SHIFT_X

# ---------- CJK æŠ˜ã‚Šè¿”ã— ----------
def wrap_cjk(text: str, width: int = 16) -> str:
    if re.search(r"[\u3040-\u30ff\u4e00-\u9fff]", text):
        return "\n".join(textwrap.wrap(text, width, break_long_words=True))
    return text

# ---------- ãƒ•ã‚©ãƒ³ãƒˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ ----------
for f in (FONT_LATN, FONT_JP, FONT_KO):
    if not os.path.isfile(f):
        raise FileNotFoundError(f"Font not found: {f}")

def pick_font(text: str) -> str:
    for ch in text:
        name = ud.name(ch, "")
        if "HANGUL" in name:
            return FONT_KO
        if any(tag in name for tag in ("CJK", "HIRAGANA", "KATAKANA")):
            return FONT_JP
    return FONT_LATN

# ============ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå®šæ•°ï¼ˆæ¨ªå‹•ç”»ç”¨ï¼‰ ============
SCREEN_W, SCREEN_H = 1920, 1080
DEFAULT_FSIZE_TOP  = 75   # â† ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¸Šæ®µã‚µã‚¤ã‚º
DEFAULT_FSIZE_BOT  = 70   # â† ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¸‹æ®µã‚µã‚¤ã‚º
TEXT_W             = 1500
POS_Y              = 880
LINE_GAP           = 26
BOTTOM_MARGIN      = 30
PAD_X, PAD_Y       = 22, 16
# ===================================================

# ---------- åŠé€æ˜é»’å¸¯ ----------
def _bg(txt: TextClip) -> ColorClip:
    return ColorClip((txt.w + PAD_X * 2, txt.h + PAD_Y * 2), (0, 0, 0)).with_opacity(0.55)

# ---------- ãƒ¡ã‚¤ãƒ³ãƒ“ãƒ«ãƒ‰é–¢æ•° ----------
def build_video(
    lines,
    bg_path,
    voice_mp3,
    out_mp4,
    rows: int = 2,
    fsize_top: int = DEFAULT_FSIZE_TOP,
    fsize_bot: int = DEFAULT_FSIZE_BOT,
):
    """
    lines : [(speaker, row1_text, row2_text, duration_sec), ...]
    rows  : 1 = ä¸Šæ®µã®ã¿ / 2 = ä¸Šæ®µ+ä¸‹æ®µ
    fsize_top / fsize_bot : å­—å¹•ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’å¤–éƒ¨ã‹ã‚‰å¯å¤‰æŒ‡å®š
    """
    bg_base = ImageClip(bg_path).resized((SCREEN_W, SCREEN_H))
    clips = []

    for speaker, *row_texts, dur in lines:
        # ----- ä¸Šæ®µ -----
        top_body = wrap_cjk(row_texts[0])
        top_txt  = f"{speaker}: {top_body}"
        top_clip = TextClip(
            text=top_txt,
            font=pick_font(top_body),
            font_size=fsize_top,
            color="white", stroke_color="black", stroke_width=4,
            method="caption", size=(TEXT_W, None),
        )
        top_bg   = _bg(top_clip)

        elem = [
            top_bg  .with_position((xpos(top_bg.w),  POS_Y - PAD_Y)),
            top_clip.with_position((xpos(top_clip.w), POS_Y)),
        ]
        block_h = top_bg.h

        # ----- ä¸‹æ®µ -----
        if rows >= 2:
            bot_body = wrap_cjk(row_texts[1]) + "\n "
            bot_clip = TextClip(
                text=bot_body,
                font=pick_font(bot_body),
                font_size=fsize_bot,
                color="white", stroke_color="black", stroke_width=4,
                method="caption", size=(TEXT_W, None),
            )
            bot_bg = _bg(bot_clip)
            y_bot  = POS_Y + top_bg.h + LINE_GAP
            elem += [
                bot_bg  .with_position((xpos(bot_bg.w),  y_bot - PAD_Y)),
                bot_clip.with_position((xpos(bot_clip.w), y_bot)),
            ]
            block_h += LINE_GAP + bot_bg.h

        # ----- ã¯ã¿å‡ºã—è£œæ­£ -----
        overflow = POS_Y + block_h + BOTTOM_MARGIN - SCREEN_H
        if overflow > 0:
            elem = [c.with_position((c.pos(0)[0], c.pos(0)[1] - overflow)) for c in elem]

        # ----- åˆæˆ -----
        comp = CompositeVideoClip([bg_base, *elem]).with_duration(dur)
        clips.append(comp)

    video = concatenate_videoclips(clips, method="compose").with_audio(AudioFileClip(voice_mp3))
    video.write_videofile(out_mp4, fps=30, codec="libx264", audio_codec="aac")
# =====================================================
# =====================================================
PY
# =====================================================
cat > translate.py <<'PY'
# translate.py
"""GPT-ãƒ™ãƒ¼ã‚¹ã®æ±ç”¨ç¿»è¨³ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â€“ ä»»æ„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªå¯¾å¿œ
   â— ãƒªãƒˆãƒ©ã‚¤ï¼æ”¹è¡Œé™¤å»ï¼å¤±æ•—ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ä»˜ãæ”¹è‰¯ç‰ˆ
"""
from __future__ import annotations

import re, time, random, logging
from openai import OpenAI
from config import OPENAI_API_KEY

client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¢ã«ç›®çš„è¨€èªã‚‰ã—ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ç°¡æ˜“åˆ¤å®š
# ï¼ˆen / ja / ko ã®ã¿å³å¯†ã€ãã®ä»–ã¯å¸¸ã«ç¿»è¨³ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _looks_like(text: str, lang: str) -> bool:
    if lang == "en":
        return all(ord(c) < 128 for c in text)           # å®Œå…¨ ASCII
    if lang == "ja":
        return (bool(set(text) & {chr(i) for i in range(0x3040, 0x30FF)})  # ã²ã‚‰ã‚«ãƒŠ
                or bool(re.search(r"[\u4E00-\u9FFF]", text)))              # æ¼¢å­—
    if lang == "ko":
        return bool(re.search(r"[\uAC00-\uD7AF]", text)) # ãƒãƒ³ã‚°ãƒ«
    return False
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


MAX_RETRY = 3      # â†© API ã®ä¸€æ™‚å¤±æ•—ã«å‚™ãˆã¦æœ€å¤§ 3 å›
BACKOFF   = 1.5    # â†© ãƒªãƒˆãƒ©ã‚¤é–“éš”ï¼ˆç§’ï¼‰

def translate(text: str, target: str) -> str:
    """
    text   : åŸæ–‡
    target : 'en', 'ja', 'ko', 'id', 'pt', â€¦ ISO-639-1
    å¤±æ•—æ™‚ : `[ID unavailable]` ã®ã‚ˆã†ãªç›®å°ã‚’è¿”ã™
    """
    if _looks_like(text, target):
        return text

    system_prompt = (
        "You are a professional translator. "
        f"Translate the following text into {target.upper()} accurately. "
        "Return the translation only."
    )

    last_err: Exception | None = None
    for attempt in range(1, MAX_RETRY + 1):
        try:
            rsp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user",   "content": text},
                ],
                temperature=0.2,
            )
            out = rsp.choices[0].message.content.strip().replace("\n", " ")
            return out or text        # å¿œç­”ç©ºãªã‚‰åŸæ–‡ã§ä»£ç”¨
        except Exception as e:
            last_err = e
            if attempt == MAX_RETRY:          # ã“ã‚ŒãŒæœ€å¾Œã®è©¦è¡Œ
                break
            time.sleep(BACKOFF + random.random())  # å°‘ã—ã‚¸ãƒƒã‚¿ãƒ¼ã‚’å…¥ã‚Œã¦å¾…æ©Ÿ

    # ---- ã“ã“ã«æ¥ãŸã‚‰å…¨ãƒªãƒˆãƒ©ã‚¤å¤±æ•— ----
    logging.warning("Translate error (%s â†’ %s): %s", text[:40], target, last_err)
    return f"[{target.upper()} unavailable]"

PY
cat > upload_youtube.py <<'PY'
# ================= upload_youtube.py =================
"""
YouTube ã¸å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚
è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå¯¾å¿œï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’ account ãƒ©ãƒ™ãƒ«ã§åˆ‡æ›¿ï¼‰ã€‚
"""

from pathlib import Path
from typing import List, Optional
import pickle, re, logging

from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http      import MediaFileUpload
from google.auth.transport.requests import Request

# â”€â”€ OAuth / API è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCOPES = ["https://www.googleapis.com/auth/youtube.upload"]
DEFAULT_TOKEN_DIR = Path("tokens")          # ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€
DEFAULT_TOKEN_DIR.mkdir(exist_ok=True)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


# ------------------------------------------------------
# âœ… è¿½åŠ : ã‚«ã‚¹ã‚¿ãƒ ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼
def _set_thumbnail(service, video_id: str, thumb_path: Path):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ video_id ã« thumb_path ã‚’é©ç”¨"""
    service.thumbnails().set(
        videoId=video_id,
        media_body=str(thumb_path)
    ).execute()
# ------------------------------------------------------


def _get_service(account_label: str = "default"):
    """
    account_label : ä»»æ„ã®è­˜åˆ¥å­ã€‚è¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ token_<label>.pkl ã‚’ä½¿ã„åˆ†ã‘ã‚‹ã€‚
    """
    token_path = DEFAULT_TOKEN_DIR / f"token_{account_label}.pkl"

    if token_path.exists():
        creds = pickle.loads(token_path.read_bytes())
        # æœ‰åŠ¹æœŸé™åˆ‡ã‚Œãªã‚‰è‡ªå‹•ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
    else:
        flow = InstalledAppFlow.from_client_secrets_file(
            "client_secret.json", SCOPES
        )
        creds = flow.run_local_server(port=0)
        token_path.write_bytes(pickle.dumps(creds))

    return build("youtube", "v3", credentials=creds)


# â”€â”€ ã‚¿ã‚¤ãƒˆãƒ«å®‰å…¨åŒ–ï¼ˆå¿µã®ãŸã‚ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _sanitize_title(raw: str) -> str:
    """ç©ºãƒ»æ”¹è¡Œå…¥ã‚Šã‚’é˜²ãã€100å­—ä»¥å†…ã«ä¸¸ã‚ã‚‹"""
    title = re.sub(r"[\s\u3000]+", " ", raw).strip()
    if len(title) > 100:
        title = title[:97] + "..."
    return title or "Auto Short #Shorts"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def upload(
    video_path: Path,
    title: str,
    desc: str,
    tags: Optional[List[str]] = None,
    privacy: str = "public",
    account: str = "default",
    thumbnail: Path | None = None,          # â˜… è¿½åŠ 
):
    """
    video_path : Path to .mp4
    title      : YouTube title
    desc       : Descriptionï¼ˆ0â€“5000 æ–‡å­—ï¼‰
    tags       : ["tag1", ...]   (optional, æœ€å¤§ 500 å€‹)
    privacy    : "public" / "unlisted" / "private"
    account    : token ãƒ©ãƒ™ãƒ«ï¼ˆè¤‡æ•°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ‡æ›¿ç”¨ï¼‰
    thumbnail  : Path to .jpg / .pngï¼ˆã‚«ã‚¹ã‚¿ãƒ ã‚µãƒ ãƒï¼‰â€»ä»»æ„
    """
    service = _get_service(account)

    # ---- æœ€çµ‚ã‚¬ãƒ¼ãƒ‰ ----
    title = _sanitize_title(title)
    if len(desc) > 5000:
        desc = desc[:4997] + "..."

    body = {
        "snippet": {
            "title":       title,
            "description": desc,
            "tags":        tags or [],
            "categoryId":  "27",        # 27 = Education
        },
        "status": {
            "privacyStatus": privacy,
        },
    }

    media = MediaFileUpload(str(video_path), chunksize=-1, resumable=True)
    req   = service.videos().insert(
        part="snippet,status",
        body=body,
        media_body=media,
    )
    resp = req.execute()

    video_id = resp["id"]
    url = f"https://youtu.be/{video_id}"
    print("âœ… YouTube Upload Done â†’", url)

    # ---- ã‚«ã‚¹ã‚¿ãƒ ã‚µãƒ ãƒã‚¤ãƒ« ----
    if thumbnail and thumbnail.exists():
        _set_thumbnail(service, video_id, thumbnail)
        print("ğŸ–¼  Custom thumbnail set.")

    logging.info("YouTube URL: %s (account=%s)", url, account)
    return url
# ====================================================
# ====================================================
PY

cat > thumbnail.py <<'PY'
# thumbnail.py â€“ perfectly centered bright glass panel + pure-white caption
from pathlib import Path
from io import BytesIO
import textwrap, logging, requests
from PIL import (
    Image, ImageDraw, ImageFont, ImageFilter,
    ImageEnhance, ImageOps                    # ImageOps.fit ç”¨
)
from openai import OpenAI
from config import OPENAI_API_KEY, UNSPLASH_ACCESS_KEY
from translate import translate

# ------------ Canvas ---------------------------------
W, H = 1280, 720

# ------------ Font set --------------------------------
FONT_DIR   = Path(__file__).parent / "fonts"         # æ—¢å­˜å­—å¹•ã¨åŒã˜å ´æ‰€
FONT_LATN  = FONT_DIR / "RobotoSerif_36pt-Bold.ttf"  # ãƒ©ãƒ†ãƒ³
FONT_CJK   = FONT_DIR / "NotoSansJP-Bold.ttf"        # æ¼¢å­—ãƒ»ã‹ãª
FONT_KO    = FONT_DIR / "malgunbd.ttf"               # í•œê¸€ (Windows æ¨™æº– Bold)

for fp in (FONT_LATN, FONT_CJK, FONT_KO):
    if not fp.exists():
        raise FileNotFoundError(f"Font missing: {fp}")

def pick_font(text: str) -> str:
    """æ–‡å­—ã‚³ãƒ¼ãƒ‰ã§é©åˆ‡ãªãƒ•ã‚©ãƒ³ãƒˆã‚’è¿”ã™"""
    for ch in text:
        cp = ord(ch)
        if 0xAC00 <= cp <= 0xD7A3:        # í•œê¸€
            return str(FONT_KO)
        if (0x4E00 <= cp <= 0x9FFF) or (0x3040 <= cp <= 0x30FF):
            return str(FONT_CJK)          # CJK/ã‹ãª
    return str(FONT_LATN)

# ------------ Caption sizes / wrapping ---------------
F_H1, F_H2          = 100, 70
WRAP_H1, WRAP_H2    = 16, 20

# ------------ Badge -----------------------------------
BADGE_BASE   = "Lesson"
BADGE_SIZE   = 60
BADGE_POS    = (40, 30)

client = OpenAI(api_key=OPENAI_API_KEY)

# ------------------------------------------------------ Unsplash BG
def _unsplash(topic: str) -> Image.Image:
    """
    Unsplash landscape â†’ 1280Ã—720 central fit.
    é»’å¸¯ãªã—ã§å¿…ãšåŸ‹ã‚ã‚‹ã€‚å¤±æ•—æ™‚ã¯ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼å˜è‰²ã€‚
    """
    if not UNSPLASH_ACCESS_KEY:
        return Image.new("RGB", (W, H), (35, 35, 35))

    url = (
        "https://api.unsplash.com/photos/random"
        f"?query={requests.utils.quote(topic)}"
        f"&orientation=landscape&client_id={UNSPLASH_ACCESS_KEY}"
    )
    try:
        r = requests.get(url, timeout=15); r.raise_for_status()
        img_url = r.json().get("urls", {}).get("regular")
        if not img_url:
            raise ValueError("Unsplash: no image url")
        img = Image.open(BytesIO(requests.get(img_url, timeout=15).content)).convert("RGB")
    except Exception:
        logging.exception("[Unsplash]")
        return Image.new("RGB", (W, H), (35, 35, 35))

    img = ImageOps.fit(img, (W, H), Image.LANCZOS, centering=(0.5, 0.5))
    img = img.filter(ImageFilter.GaussianBlur(2)).convert("RGBA")
    img.alpha_composite(Image.new("RGBA", (W, H), (0, 0, 0, 77)))   # 30 % æš—å¹•
    return img

# ------------------------------------------------------ GPT Caption
def _caption(topic: str, lang: str) -> str:
    prompt = (
        "You are a YouTube Shorts copywriter. "
        f"Give TWO catchy phrases (â‰¤18 chars) in {lang.upper()} "
        f"about: {topic}. Separate with '|'."
    )
    return client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    ).choices[0].message.content.strip()

# ------------------------------------------------------ helpers
def _txt_size(draw: ImageDraw.ImageDraw, txt: str, font: ImageFont.FreeTypeFont):
    if hasattr(draw, "textbbox"):
        x1, y1, x2, y2 = draw.textbbox((0, 0), txt, font=font)
        return x2 - x1, y2 - y1
    return draw.textsize(txt, font=font)

# ------------------------------------------------------ draw core
def _draw(img: Image.Image, cap: str, badge_txt: str) -> Image.Image:
    if img.mode != "RGBA":
        img = img.convert("RGBA")
    draw = ImageDraw.Draw(img)

    l1, l2  = (cap.split("|") + [""])[:2]
    l1, l2  = l1.strip(), l2.strip()

    f1 = ImageFont.truetype(pick_font(l1),          F_H1)
    f2 = ImageFont.truetype(pick_font(l2 or l1),    F_H2)

    t1 = textwrap.fill(l1, WRAP_H1)
    t2 = textwrap.fill(l2, WRAP_H2) if l2 else ""

    w1, h1 = _txt_size(draw, t1, f1)
    w2, h2 = (_txt_size(draw, t2, f2) if t2 else (0, 0))

    stroke = 4
    tw = max(w1, w2) + stroke*2
    th = h1 + (h2 + 12 if t2 else 0)

    # ---- panel auto-padding ---------------------------------------
    BASE_PAD_X, BASE_PAD_Y = 60, 40
    pad_x = min(BASE_PAD_X, max(20, (W - tw)//2))
    pad_y = min(BASE_PAD_Y, max(20, (H - th)//2))

    pw, ph = tw + pad_x*2, th + pad_y*2
    x_panel = (W - pw)//2
    y_panel = (H - ph)//2
    x_txt   = x_panel + pad_x
    y_txt   = y_panel + pad_y

    # ---- glass panel ---------------------------------------------
    radius = 35
    panel_bg = img.crop((x_panel, y_panel, x_panel+pw, y_panel+ph)) \
                  .filter(ImageFilter.GaussianBlur(12)).convert("RGBA")
    veil     = Image.new("RGBA", (pw, ph), (255,255,255,77))
    panel    = Image.alpha_composite(panel_bg, veil)

    mask = Image.new("L", (pw, ph), 0)
    ImageDraw.Draw(mask).rounded_rectangle([0,0,pw-1,ph-1], radius, fill=255)
    panel.putalpha(mask)

    border = Image.new("RGBA", (pw, ph))
    ImageDraw.Draw(border).rounded_rectangle(
        [0,0,pw-1,ph-1], radius, outline=(255,255,255,120), width=2)
    panel = Image.alpha_composite(panel, border)
    img.paste(panel, (x_panel, y_panel), panel)

    # ---- glow -----------------------------------------------------
    glow = Image.new("RGBA", img.size, (0,0,0,0))
    gd   = ImageDraw.Draw(glow)
    gd.text((x_txt, y_txt), t1, font=f1, fill=(255,255,255,255))
    if t2:
        gd.text((x_txt, y_txt+h1+12), t2, font=f2, fill=(255,255,255,255))
    glow = glow.filter(ImageFilter.GaussianBlur(14))
    glow = ImageEnhance.Brightness(glow).enhance(1.2)
    img.alpha_composite(glow)

    # ---- final text ----------------------------------------------
    draw.text((x_txt, y_txt), t1, font=f1, fill=(255,255,255),
              stroke_width=stroke, stroke_fill=(0,0,0))
    if t2:
        draw.text((x_txt, y_txt+h1+12), t2, font=f2,
                  fill=(255,255,255), stroke_width=stroke, stroke_fill=(0,0,0))

    # ---- badge ----------------------------------------------------
    bf  = ImageFont.truetype(pick_font(badge_txt), BADGE_SIZE)
    draw.text(BADGE_POS, badge_txt, font=bf,
              fill=(255,255,255), stroke_width=3, stroke_fill=(0,0,0))
    return img

# ------------------------------------------------------ public
def make_thumbnail(topic: str, lang: str, out: Path):
    bg    = _unsplash(topic)
    cap   = _caption(topic, lang)
    badge = translate(BADGE_BASE, lang) or BADGE_BASE
    thumb = _draw(bg, cap, badge)
    thumb.convert("RGB").save(out, "JPEG", quality=92)
    logging.info("ğŸ–¼ï¸  Thumbnail saved â†’ %s", out.name)

PY

cat > audio_fx.py <<'PY'
# audio_fx.py â€“ â€œè‰¯ã„ãƒã‚¤ã‚¯é¢¨â€ (deesser éä¾å­˜ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
import subprocess, shutil
from pathlib import Path

# -----------------------------------------------------------
# FILTER chain
#   1) highpass 60 Hz         : ç©ºèª¿/æœºæŒ¯å‹•ã‚«ãƒƒãƒˆ
#   2) lowpass  15 kHz        : ãƒ¢ã‚¹ã‚­ãƒ¼ãƒˆãƒã‚¤ã‚ºæŠ‘åˆ¶
#   3) presence EQ 4 kHz +3dB : æ˜ç­åº¦
#   4) soft de-ess  8 kHz âˆ’2dB: æ­¯æ“¦éŸ³ã‚’ã‚„ã‚„æŠ‘ãˆã‚‹ (simple EQ)
#   5) soft compressor        : ratio 2:1 ã§è‡ªç„¶ã«
#   6) loudnorm (-16 LUFS)    : ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆæ¨™æº–ãƒ©ã‚¦ãƒ‰ãƒã‚¹
FILTER = (
    "highpass=f=60,"
    "lowpass=f=15000,"
    "equalizer=f=4000:width_type=h:width=150:g=3,"
    "equalizer=f=8000:width_type=h:width=300:g=-2,"
    "acompressor=threshold=-18dB:ratio=2:knee=2:attack=15:release=200,"
    "loudnorm=I=-16:TP=-1.5:LRA=11"
)
# -----------------------------------------------------------

def enhance(in_mp3: Path, out_mp3: Path):
    """
    in_mp3  : å…¥åŠ› mp3
    out_mp3 : æ•´éŸ³å¾Œ mp3
    """
    if not shutil.which("ffmpeg"):
        raise RuntimeError("ffmpeg ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚PATH ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    cmd = [
        "ffmpeg", "-y", "-i", str(in_mp3),
        "-af", FILTER,
        "-ar", "48000",                # 48 kHz ã«çµ±ä¸€ï¼ˆå¿…è¦ã«å¿œã˜ã¦ 44100ï¼‰
        str(out_mp3)
    ]

    # æ¨™æº–å‡ºåŠ›ãƒ»ã‚¨ãƒ©ãƒ¼ã‚’ãã®ã¾ã¾è¡¨ç¤ºã—ã€å¤±æ•—æ™‚ã¯å†…å®¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãå‡ºåŠ›
    proc = subprocess.run(cmd, text=True)
    if proc.returncode != 0:
        raise RuntimeError(
            f"ffmpeg returned {proc.returncode}. "
            "ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã«ç›´æ¥è²¼ã‚Šä»˜ã‘ã¦ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "deesser ãƒ•ã‚£ãƒ«ã‚¿ãŒå¿…è¦ãªã‚‰ã€FFmpeg full build ã‚’å°å…¥ã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚Šã¾ã™ã€‚"
        )
PY

cat > audio_fx.py <<'PY'
# audio_fx.py â€“ â€œè‰¯ã„ãƒã‚¤ã‚¯é¢¨â€ (deesser éä¾å­˜ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
import subprocess, shutil
from pathlib import Path

# -----------------------------------------------------------
# FILTER chain
#   1) highpass 60 Hz         : ç©ºèª¿/æœºæŒ¯å‹•ã‚«ãƒƒãƒˆ
#   2) lowpass  15 kHz        : ãƒ¢ã‚¹ã‚­ãƒ¼ãƒˆãƒã‚¤ã‚ºæŠ‘åˆ¶
#   3) presence EQ 4 kHz +3dB : æ˜ç­åº¦
#   4) soft de-ess  8 kHz âˆ’2dB: æ­¯æ“¦éŸ³ã‚’ã‚„ã‚„æŠ‘ãˆã‚‹ (simple EQ)
#   5) soft compressor        : ratio 2:1 ã§è‡ªç„¶ã«
#   6) loudnorm (-16 LUFS)    : ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆæ¨™æº–ãƒ©ã‚¦ãƒ‰ãƒã‚¹
FILTER = (
    "highpass=f=60,"
    "lowpass=f=10500,"
    "equalizer=f=4000:width_type=h:width=150:g=3,"
    "equalizer=f=8000:width_type=h:width=300:g=-2,"
    "acompressor=threshold=-18dB:ratio=2:knee=2:attack=15:release=200,"
    "loudnorm=I=-16:TP=-1.5:LRA=11"
)
# -----------------------------------------------------------

def enhance(in_mp3: Path, out_mp3: Path):
    """
    in_mp3  : å…¥åŠ› mp3
    out_mp3 : æ•´éŸ³å¾Œ mp3
    """
    if not shutil.which("ffmpeg"):
        raise RuntimeError("ffmpeg ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚PATH ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    cmd = [
        "ffmpeg", "-y", "-i", str(in_mp3),
        "-af", FILTER,
        "-ar", "48000",                # 48 kHz ã«çµ±ä¸€ï¼ˆå¿…è¦ã«å¿œã˜ã¦ 44100ï¼‰
        str(out_mp3)
    ]

    # æ¨™æº–å‡ºåŠ›ãƒ»ã‚¨ãƒ©ãƒ¼ã‚’ãã®ã¾ã¾è¡¨ç¤ºã—ã€å¤±æ•—æ™‚ã¯å†…å®¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãå‡ºåŠ›
    proc = subprocess.run(cmd, text=True)
    if proc.returncode != 0:
        raise RuntimeError(
            f"ffmpeg returned {proc.returncode}. "
            "ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã«ç›´æ¥è²¼ã‚Šä»˜ã‘ã¦ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "deesser ãƒ•ã‚£ãƒ«ã‚¿ãŒå¿…è¦ãªã‚‰ã€FFmpeg full build ã‚’å°å…¥ã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚Šã¾ã™ã€‚"
        )
PY


cat > main.py <<'PY'
# ======================= main.py ==========================
#!/usr/bin/env python
"""
main.py â€“ GPT ã§ä¼šè©± â†’ OpenAI TTS â†’ å¤šæ®µå­—å¹•ä»˜ãç¸¦å‹•ç”» (1080Ã—1920)
          combos.yaml ã®çµ„ã¿åˆã‚ã›ã”ã¨ã«ç”Ÿæˆã—ã€
          â”€â”€ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: YouTube ã¸è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
          â”€â”€ --no-upload ã‚’ä»˜ã‘ã‚‹ã¨ãƒ­ãƒ¼ã‚«ãƒ«å‡ºåŠ›ã®ã¿
"""
from datetime import datetime
import argparse, logging, yaml, re
from pathlib import Path
from shutil import rmtree
from pydub import AudioSegment
from openai import OpenAI

from config          import BASE, OUTPUT, TEMP
from dialogue        import make_dialogue
from translate       import translate
from tts_openai      import speak
from podcast         import concat_mp3
from bg_image        import fetch as fetch_bg
from subtitle_video  import build_video
from upload_youtube  import upload
from audio_fx        import enhance   # éŸ³è³ªãƒ•ã‚£ãƒ«ã‚¿

GPT = OpenAI()

# â”€â”€ è¨€èªã‚³ãƒ³ãƒœèª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open(BASE / "combos.yaml", encoding="utf-8") as f:
    COMBOS = yaml.safe_load(f)["combos"]

# â”€â”€ TEMP ã‚’æ¯å›ç©ºã« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reset_temp():
    if TEMP.exists():
        rmtree(TEMP)
    TEMP.mkdir(exist_ok=True)

# â”€â”€ ã‚¿ã‚¤ãƒˆãƒ«æ•´å½¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sanitize_title(raw: str) -> str:
    title = re.sub(r"[\s\u3000]+", " ", raw).strip()
    return title[:97] + "â€¦" if len(title) > 100 else title or "Auto Short"

# â”€â”€ å…±é€š: ãƒ—ãƒ©ã‚¤ãƒãƒªè¨€èªæ±ºå®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _primary_lang(audio_lang: str, subs: list[str]) -> str:
    """å­—å¹•ãŒ 2 è¡Œä»¥ä¸Šã‚ã‚Œã° 2 è¡Œç›®ã‚’å„ªå…ˆã€ç„¡ã‘ã‚Œã°éŸ³å£°è¨€èª"""
    return subs[1] if len(subs) > 1 else audio_lang

# â”€â”€ GPT ã‚¿ã‚¤ãƒˆãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_title(topic: str, audio_lang: str, subs: list[str]) -> str:
    primary = _primary_lang(audio_lang, subs)
    prompt  = (
        "You are a YouTube Shorts copywriter.\n"
        "Write a catchy title (â‰¤55 ASCII or 28 JP chars).\n"
        f"Main part in {primary.upper()}, then ' | ' and an English gloss, end with #Shorts.\n"
        f"Topic: {topic}"
    )
    rsp = GPT.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    return sanitize_title(rsp.choices[0].message.content.strip())

# â”€â”€ GPT èª¬æ˜æ¬„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_desc(topic: str, audio_lang: str, subs: list[str]) -> str:
    primary = _primary_lang(audio_lang, subs)
    prompt = (
        f"Write one sentence (â‰¤90 characters) in {primary.upper()} summarising "
        f'\"{topic}\" and ending with a short call-to-action.'
    )
    rsp = GPT.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
    )
    base = rsp.choices[0].message.content.strip()

    hashtags = ["#Shorts", "#LanguageLearning"]
    if primary != "en":
        hashtags.append(f"#Learn{primary.upper()}")
    return f"{base} {' '.join(hashtags[:3])}"

# â”€â”€ ãƒ¡ã‚¿ tags ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LANG_NAME = {
    "en": "English", "pt": "Portuguese", "id": "Indonesian",
    "ja": "Japanese", "ko": "Korean", "es": "Spanish"
}
def make_tags(topic: str, audio_lang: str, subs: list[str]) -> list[str]:
    tags = [topic, "language learning", "Shorts",
            f"{LANG_NAME.get(audio_lang,'')} speaking"]
    for code in subs[1:]:
        if code in LANG_NAME:
            tags.extend([f"{LANG_NAME[code]} subtitles", f"Learn {LANG_NAME[code]}"])
    return list(dict.fromkeys(tags))[:15]

# â”€â”€ å…¨ã‚³ãƒ³ãƒœå‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_all(topic: str, turns: int, privacy: str, do_upload: bool):
    for combo in COMBOS:
        run_one(topic, turns,
                combo["audio"], combo["subs"],
                yt_privacy=privacy,
                account   =combo.get("account", "default"),
                do_upload =do_upload)

# â”€â”€ å˜ä¸€ã‚³ãƒ³ãƒœå‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_one(topic: str, turns: int, audio_lang: str, subs: list[str],
            yt_privacy: str, account: str, do_upload: bool):

    reset_temp()

    # 1) ä¼šè©±ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    dialogue = make_dialogue(topic, audio_lang, turns)

    # 2) éŸ³å£°åˆæˆ & ç¿»è¨³
    mp_parts, durations, sub_rows = [], [], [[] for _ in subs]
    for i, (spk, line) in enumerate(dialogue, 1):
        mp = TEMP / f"{i:02d}.mp3"
        speak(audio_lang, spk, line, mp)
        mp_parts.append(mp)
        durations.append(AudioSegment.from_file(mp).duration_seconds)
        for r, lang in enumerate(subs):
            sub_rows[r].append(line if lang == audio_lang else translate(line, lang))

    concat_mp3(mp_parts, TEMP / "full_raw.mp3")      # ã¾ãšç”ŸéŸ³å£°ã‚’çµåˆ
    enhance(TEMP / "full_raw.mp3", TEMP / "full.mp3")# é«˜éŸ³è³ªåŒ–ã‚’é©ç”¨

    # 3) èƒŒæ™¯ç”»åƒ
    bg_png = TEMP / "bg.png"; fetch_bg(topic, bg_png)

    # 4) å‹•ç”»ç”Ÿæˆ
    stamp   = datetime.now().strftime("%Y%m%d_%H%M%S")
    outfile = OUTPUT / f"{audio_lang}-{'_'.join(subs)}_{stamp}.mp4"
    lines   = [(spk, *[row[i] for row in sub_rows], dur)
               for i, ((spk, _), dur) in enumerate(zip(dialogue, durations))]
    build_video(lines, bg_png, TEMP / "full.mp3", outfile, rows=len(subs))
    logging.info("âœ… Video saved: %s", outfile.name)

    if not do_upload:
        logging.info("â­ï¸  --no-upload æŒ‡å®šã®ãŸã‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return

    # 5) ãƒ¡ã‚¿ & ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    title = make_title(topic, audio_lang, subs)
    desc  = make_desc(topic, audio_lang, subs)
    tags  = make_tags(topic, audio_lang, subs)
    upload(outfile, title=title, desc=desc, tags=tags,
           privacy=yt_privacy, account=account)

# â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("topic", help="ä¼šè©±ãƒ†ãƒ¼ãƒ (ä¾‹: 'Japanese cuisine')")
    ap.add_argument("--turns", type=int, default=8)
    ap.add_argument("--privacy", default="unlisted",
                    choices=["public", "unlisted", "private"])
    ap.add_argument("--no-upload", action="store_true",
                    help="å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ã ã‘ã§ YouTube ã¸ã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãªã„")
    args = ap.parse_args()

    run_all(args.topic, turns=args.turns,
            privacy=args.privacy, do_upload=(not args.no_upload))
# =========================================================
PY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

echo "âœ… Podcastâ€‘only minimal modules generated."
